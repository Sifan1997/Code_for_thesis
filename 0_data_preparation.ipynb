{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-18T10:13:32.582188Z",
     "start_time": "2024-08-18T10:13:32.560592Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Read the UN Comtrade data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "\n",
    "# Specify the path to the folder containing CSV files\n",
    "folder_path = '../data/raw/MonthlyTradeData_HS8542'\n",
    "\n",
    "# Get a list of all files in the folder\n",
    "files = [file for file in os.listdir(folder_path)]\n",
    "\n",
    "# Create an empty list to store DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Loop through each CSV file and read it into a DataFrame\n",
    "for file in files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    df = pd.read_csv(file_path, encoding='unicode_escape')\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "monthly_trade_data = pd.concat(dfs)\n",
    "\n",
    "# Keep the necessary columns\n",
    "monthly_trade_data = monthly_trade_data[\n",
    "    ['Period', 'ReporterISO', 'ReporterDesc', 'PartnerISO', 'PartnerDesc', 'PrimaryValue']\n",
    "]\n",
    "\n",
    "# Convert the 'Period' column to datetime format\n",
    "monthly_trade_data['Period'] = pd.to_datetime(monthly_trade_data['Period'], format='%Y%m')\n",
    "\n",
    "# Filter the 'Period' to keep data between 2010-01-01 and 2023-08-01\n",
    "monthly_trade_data = monthly_trade_data[\n",
    "    (monthly_trade_data['Period'] >= '2010-01-01') & \n",
    "    (monthly_trade_data['Period'] <= '2023-08-01')\n",
    "]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T07:44:42.156950Z",
     "start_time": "2024-08-17T07:44:39.436251Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "\n",
    "# Specify the path to the folder containing CSV files\n",
    "folder_path_tw = '../data/raw/8542_extra'\n",
    "\n",
    "# Get a list of all files in the folder\n",
    "files = os.listdir(folder_path_tw)\n",
    "\n",
    "# Create an empty list to store DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Loop through each CSV file and read it into a DataFrame\n",
    "for file in files:\n",
    "    file_path = os.path.join(folder_path_tw, file)\n",
    "    df = pd.read_csv(file_path, encoding='unicode_escape')\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "monthly_trade_data_tw = pd.concat(dfs)\n",
    "\n",
    "# Keep the necessary columns\n",
    "monthly_trade_data_tw = monthly_trade_data_tw[\n",
    "    ['Period', 'ReporterISO', 'ReporterDesc', 'PartnerISO', 'PartnerDesc', 'PrimaryValue']\n",
    "]\n",
    "\n",
    "# Convert the 'Period' column to datetime format\n",
    "monthly_trade_data_tw['Period'] = pd.to_datetime(monthly_trade_data_tw['Period'], format='%Y%m')\n",
    "\n",
    "# Filter the 'Period' to keep data between 2010-01-01 and 2023-08-01\n",
    "monthly_trade_data_tw = monthly_trade_data_tw[\n",
    "    (monthly_trade_data_tw['Period'] >= '2010-01-01') & \n",
    "    (monthly_trade_data_tw['Period'] <= '2023-08-01')\n",
    "]\n",
    "\n",
    "# Exchange the positions of Reporter and Partner since we want to use the import data as an addition to export data of TW\n",
    "monthly_trade_data_tw.rename(columns={\n",
    "    'ReporterISO': 'PartnerISO_1',\n",
    "    'ReporterDesc': 'PartnerDesc_1',\n",
    "    'PartnerISO': 'ReporterISO_1',\n",
    "    'PartnerDesc': 'ReporterDesc_1'\n",
    "}, inplace=True)\n",
    "\n",
    "monthly_trade_data_tw.rename(columns={\n",
    "    'ReporterISO_1': 'ReporterISO',\n",
    "    'ReporterDesc_1': 'ReporterDesc',\n",
    "    'PartnerISO_1': 'PartnerISO',\n",
    "    'PartnerDesc_1': 'PartnerDesc'\n",
    "}, inplace=True)\n",
    "\n",
    "# Extract the needed columns\n",
    "monthly_trade_data_tw = monthly_trade_data_tw[\n",
    "    ['Period', 'ReporterISO', 'ReporterDesc', 'PartnerISO', 'PartnerDesc', 'PrimaryValue']\n",
    "]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T07:44:42.305472Z",
     "start_time": "2024-08-17T07:44:42.159316Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Period ReporterISO ReporterDesc PartnerISO PartnerDesc  PrimaryValue\n",
      "0 2015-01-01         DZA      Algeria        W00       World      2628.566\n",
      "1 2015-01-01         DZA      Algeria        USA         USA      2628.566\n",
      "2 2015-01-01         AGO       Angola        W00       World      2982.590\n",
      "3 2015-01-01         AGO       Angola        FRA      France       495.050\n",
      "4 2015-01-01         AGO       Angola        NAM     Namibia      2426.630\n",
      "(506633, 6)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Concatenate the two DataFrames into a single DataFrame\n",
    "monthly_trade_data = pd.concat([monthly_trade_data, monthly_trade_data_tw])\n",
    "\n",
    "# Display the first few rows of the concatenated DataFrame\n",
    "print(monthly_trade_data.head())\n",
    "\n",
    "# Display the shape of the concatenated DataFrame\n",
    "print(monthly_trade_data.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T07:44:42.328311Z",
     "start_time": "2024-08-17T07:44:42.307975Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed shape: (460996, 6)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 460996 entries, 1 to 986\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count   Dtype         \n",
      "---  ------        --------------   -----         \n",
      " 0   Period        460996 non-null  datetime64[ns]\n",
      " 1   ReporterISO   460996 non-null  object        \n",
      " 2   ReporterDesc  460996 non-null  object        \n",
      " 3   PartnerISO    460996 non-null  object        \n",
      " 4   PartnerDesc   460996 non-null  object        \n",
      " 5   PrimaryValue  460996 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(1), object(4)\n",
      "memory usage: 24.6+ MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to strip leading and trailing spaces from string values\n",
    "def strip_categorical(value):\n",
    "    if isinstance(value, str):\n",
    "        return value.strip()\n",
    "    return value\n",
    "\n",
    "# Function to replace country codes and clean DataFrame\n",
    "def replace_and_delete_countries(df):\n",
    "    # Apply the strip_categorical function to the entire DataFrame\n",
    "    df = df.applymap(strip_categorical)\n",
    "    \n",
    "    # Replace \"Other Asia, nes\" (S19) with Taiwan, China (TWN)\n",
    "    df['ReporterISO'] = df['ReporterISO'].replace('S19', 'TWN')\n",
    "    df.loc[df['ReporterISO'] == 'TWN', 'ReporterDesc'] = 'Taiwan'\n",
    "    \n",
    "    df['PartnerISO'] = df['PartnerISO'].replace('S19', 'TWN')\n",
    "    df.loc[df['PartnerISO'] == 'TWN', 'PartnerDesc'] = 'Taiwan'\n",
    "    \n",
    "    # Drop rows containing NaN\n",
    "    df = df.dropna()\n",
    "    \n",
    "    # List of 193 ISO codes for UN members plus Taiwan\n",
    "    to_keep = [\n",
    "        \"AFG\", \"ALB\", \"DZA\", \"AND\", \"AGO\", \"ATG\", \"ARG\", \"ARM\", \"AUS\", \"AUT\", \"AZE\", \"BHS\", \n",
    "        \"BHR\", \"BGD\", \"BRB\", \"BLR\", \"BEL\", \"BLZ\", \"BEN\", \"BTN\", \"BOL\", \"BIH\", \"BWA\", \"BRA\", \n",
    "        \"BRN\", \"BGR\", \"BFA\", \"BDI\", \"CPV\", \"KHM\", \"CMR\", \"CAN\", \"CAF\", \"TCD\", \"CHL\", \"CHN\", \n",
    "        \"COL\", \"COM\", \"COG\", \"COD\", \"CRI\", \"CIV\", \"HRV\", \"CUB\", \"CYP\", \"CZE\", \"DNK\", \"DJI\", \n",
    "        \"DMA\", \"DOM\", \"ECU\", \"EGY\", \"SLV\", \"GNQ\", \"ERI\", \"EST\", \"SWZ\", \"ETH\", \"FJI\", \"FIN\", \n",
    "        \"FRA\", \"GAB\", \"GMB\", \"GEO\", \"DEU\", \"GHA\", \"GRC\", \"GRD\", \"GTM\", \"GIN\", \"GNB\", \"GUY\", \n",
    "        \"HTI\", \"HND\", \"HUN\", \"ISL\", \"IND\", \"IDN\", \"IRN\", \"IRQ\", \"IRL\", \"ISR\", \"ITA\", \"JAM\", \n",
    "        \"JPN\", \"JOR\", \"KAZ\", \"KEN\", \"KIR\", \"KWT\", \"KGZ\", \"LAO\", \"LVA\", \"LBN\", \"LSO\", \"LBR\", \n",
    "        \"LBY\", \"LIE\", \"LTU\", \"LUX\", \"MDG\", \"MWI\", \"MYS\", \"MDV\", \"MLI\", \"MLT\", \"MHL\", \"MRT\", \n",
    "        \"MUS\", \"MEX\", \"FSM\", \"MDA\", \"MCO\", \"MNG\", \"MNE\", \"MAR\", \"MOZ\", \"MMR\", \"NAM\", \"NRU\", \n",
    "        \"NPL\", \"NLD\", \"NZL\", \"NIC\", \"NER\", \"NGA\", \"PRK\", \"MKD\", \"NOR\", \"OMN\", \"PAK\", \"PLW\", \n",
    "        \"PAN\", \"PNG\", \"PRY\", \"PER\", \"PHL\", \"POL\", \"PRT\", \"QAT\", \"ROU\", \"RUS\", \"RWA\", \n",
    "        \"KNA\", \"LCA\", \"VCT\", \"WSM\", \"SMR\", \"STP\", \"SAU\", \"SEN\", \"SRB\", \"SYC\", \"SLE\", \"SGP\", \n",
    "        \"SVK\", \"SVN\", \"SLB\", \"SOM\", \"ZAF\", \"KOR\", \"SSD\", \"ESP\", \"LKA\", \"SDN\", \"SUR\", \"SWE\", \n",
    "        \"CHE\", \"SYR\", \"TJK\", \"TZA\", \"THA\", \"TLS\", \"TGO\", \"TON\", \"TTO\", \"TUN\", \"TUR\", \"TKM\", \n",
    "        \"TUV\", \"UGA\", \"UKR\", \"ARE\", \"GBR\", \"USA\", \"URY\", \"UZB\", \"VUT\", \"VEN\", \"VNM\", \"YEM\", \n",
    "        \"ZMB\", \"ZWE\", \"TWN\"\n",
    "    ]\n",
    "    \n",
    "    # Keep rows where ReporterISO and PartnerISO are in the list of countries to keep\n",
    "    df = df[df['ReporterISO'].isin(to_keep) & df['PartnerISO'].isin(to_keep)]\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply the function on monthly_TradeData\n",
    "monthly_trade_data = replace_and_delete_countries(monthly_trade_data) \n",
    "\n",
    "# Print the shape of the DataFrame after processing\n",
    "print(\"Processed shape:\", monthly_trade_data.shape)\n",
    "\n",
    "# Display a concise summary of the DataFrame\n",
    "monthly_trade_data.info()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T07:44:43.458831Z",
     "start_time": "2024-08-17T07:44:42.331580Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last Period Reporter Counts:\n",
      "LastPeriodReporter\n",
      "2023-08-01    77\n",
      "2022-12-01    10\n",
      "2023-07-01     6\n",
      "2019-12-01     4\n",
      "2021-12-01     4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Last Period Partner Counts:\n",
      "LastPeriodPartner\n",
      "2023-08-01    173\n",
      "2023-07-01      8\n",
      "2023-05-01      3\n",
      "2023-06-01      2\n",
      "2023-04-01      2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "### Can be deleted -- Used to explore the last appearance of country\n",
    "\n",
    "# Find the last periods for each country in 'ReporterDesc'\n",
    "last_appearance_reporter = (\n",
    "    monthly_trade_data.groupby('ReporterDesc')['Period']\n",
    "    .max()\n",
    "    .reset_index()\n",
    "    .rename(columns={'Period': 'LastPeriodReporter'})\n",
    ")\n",
    "\n",
    "# Find the last periods for each country in 'PartnerDesc'\n",
    "last_appearance_partner = (\n",
    "    monthly_trade_data.groupby('PartnerDesc')['Period']\n",
    "    .max()\n",
    "    .reset_index()\n",
    "    .rename(columns={'Period': 'LastPeriodPartner'})\n",
    ")\n",
    "\n",
    "# Combine both Reporter and Partner appearances into a single DataFrame\n",
    "last_appearance = pd.merge(\n",
    "    last_appearance_reporter,\n",
    "    last_appearance_partner,\n",
    "    left_on='ReporterDesc',\n",
    "    right_on='PartnerDesc',\n",
    "    how='outer'\n",
    ")\n",
    "\n",
    "# Get the number of unique periods for LastPeriodReporter and LastPeriodPartner\n",
    "num_unique_periods_reporter = last_appearance['LastPeriodReporter'].nunique()\n",
    "num_unique_periods_partner = last_appearance['LastPeriodPartner'].nunique()\n",
    "\n",
    "# Get the count of each unique period\n",
    "period_counts_reporter = last_appearance['LastPeriodReporter'].value_counts()\n",
    "period_counts_partner = last_appearance['LastPeriodPartner'].value_counts()\n",
    "\n",
    "# Display the count of each unique period\n",
    "print(\"Last Period Reporter Counts:\")\n",
    "print(period_counts_reporter.head())\n",
    "print(\"\\nLast Period Partner Counts:\")\n",
    "print(period_counts_partner.head())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T07:44:43.507379Z",
     "start_time": "2024-08-17T07:44:43.468097Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T07:44:43.508200Z",
     "start_time": "2024-08-17T07:44:43.503699Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Get the country list for all countries appeared in monthly_trade_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Name  ISO             GDP_2022              GDP_2023\n",
      "0     Algeria  DZA  225560256621.757202   239899491127.742371\n",
      "1      Angola  AGO  104399746853.401413    84722957642.375656\n",
      "2  Azerbaijan  AZE   78807470588.235306    72356176470.588242\n",
      "3   Argentina  ARG  631133384439.944458   640591410663.883423\n",
      "4   Australia  AUS  1692956646855.70166  1723827215334.706299\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 193 entries, 0 to 192\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Name      192 non-null    object\n",
      " 1   ISO       193 non-null    object\n",
      " 2   GDP_2022  192 non-null    object\n",
      " 3   GDP_2023  192 non-null    object\n",
      "dtypes: object(4)\n",
      "memory usage: 6.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_country_list(df):\n",
    "    \"\"\"\n",
    "    Extracts a unique list of countries from the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): The input DataFrame with trade data.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: A DataFrame containing unique countries with their ISO codes and names.\n",
    "    \"\"\"\n",
    "    # Select only the necessary columns\n",
    "    df = df[['ReporterISO', 'ReporterDesc', 'PartnerISO', 'PartnerDesc']]\n",
    "\n",
    "    # Create a DataFrame for Reporter countries\n",
    "    reporter_countries = df[['ReporterISO', 'ReporterDesc']].rename(columns={'ReporterISO': 'ISO', 'ReporterDesc': 'Country'})\n",
    "    \n",
    "    # Create a DataFrame for Partner countries\n",
    "    partner_countries = df[['PartnerISO', 'PartnerDesc']].rename(columns={'PartnerISO': 'ISO', 'PartnerDesc': 'Country'})\n",
    "    \n",
    "    # Concatenate both DataFrames and drop duplicates\n",
    "    countries = pd.concat([reporter_countries, partner_countries]).drop_duplicates().reset_index(drop=True)\n",
    "    \n",
    "    return countries\n",
    "\n",
    "# Apply the function to the trade data DataFrame\n",
    "countries = get_country_list(monthly_trade_data)\n",
    "\n",
    "# Read GDP data of countries\n",
    "country_gdp = pd.read_excel('../data/raw/P_Data_Extract_From_World_Development_Indicators_GDP.xlsx', sheet_name='Data', index_col=None)\n",
    "\n",
    "# Merge the country list with the GDP data\n",
    "country_info = pd.merge(country_gdp, countries[['ISO']], how='right', on='ISO')\n",
    "\n",
    "# Display the first few rows of the country_info DataFrame\n",
    "print(country_info.head())\n",
    "\n",
    "# Display a concise summary of the country_info DataFrame\n",
    "print(country_info.info())\n",
    "\n",
    "# Save the merged data to a CSV file\n",
    "country_info.to_csv('../data/processed/countries.csv', index=False, header=True)\n",
    "\n",
    "# Optional: Save to Excel file if needed\n",
    "# country_info.to_excel('../data/processed/countries.xlsx', index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T07:44:43.690081Z",
     "start_time": "2024-08-17T07:44:43.512114Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "\n",
    "# Select only the necessary columns from the DataFrame\n",
    "monthly_trade_data = monthly_trade_data[['Period', 'ReporterISO', 'PartnerISO', 'PrimaryValue']]\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "monthly_trade_data.to_csv('../data/processed/monthly_trade_data.csv', index=False, header=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T07:44:44.326625Z",
     "start_time": "2024-08-17T07:44:43.691269Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T07:44:44.331667Z",
     "start_time": "2024-08-17T07:44:44.327987Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get feature data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "TPU -- Trade policy uncertainty index https://www.policyuncertainty.com/trade_cimpr.html"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Period        TPU\n",
      "600 2010-01-01  24.490808\n",
      "601 2010-02-01  18.847337\n",
      "602 2010-03-01  28.556673\n",
      "603 2010-04-01  25.487728\n",
      "604 2010-05-01  21.410693\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 164 entries, 600 to 763\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype         \n",
      "---  ------  --------------  -----         \n",
      " 0   Period  164 non-null    datetime64[ns]\n",
      " 1   TPU     164 non-null    float64       \n",
      "dtypes: datetime64[ns](1), float64(1)\n",
      "memory usage: 3.8 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Read data from Excel file\n",
    "tpu = pd.read_excel('../data/raw/tpu_web_latest.xlsx', sheet_name='TPU_MONTHLY', index_col=None)\n",
    "\n",
    "# Select only the necessary columns\n",
    "tpu = tpu[['DATE', 'TPU']]\n",
    "\n",
    "# Rename 'DATE' to 'Period'\n",
    "tpu = tpu.rename(columns={'DATE': 'Period'})\n",
    "\n",
    "# Convert 'Period' to datetime format\n",
    "tpu['Period'] = pd.to_datetime(tpu['Period'], format='%Y-%m-%d')\n",
    "\n",
    "# Filter rows where 'Period' is between 2010-01-01 and 2023-08-01\n",
    "tpu = tpu[(tpu['Period'] >= '2010-01-01') & (tpu['Period'] <= '2023-08-01')]\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(tpu.head())\n",
    "\n",
    "# Display a concise summary of the DataFrame\n",
    "print(tpu.info())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T07:44:44.382430Z",
     "start_time": "2024-08-17T07:44:44.332120Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "GPR -- Geopolitical Risk Index https://www.matteoiacoviello.com/gpr.htm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Period        GPR\n",
      "1320 2010-01-01  91.581024\n",
      "1321 2010-02-01  80.725357\n",
      "1322 2010-03-01  74.116943\n",
      "1323 2010-04-01  88.761581\n",
      "1324 2010-05-01  88.958710\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 164 entries, 1320 to 1483\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype         \n",
      "---  ------  --------------  -----         \n",
      " 0   Period  164 non-null    datetime64[ns]\n",
      " 1   GPR     164 non-null    float64       \n",
      "dtypes: datetime64[ns](1), float64(1)\n",
      "memory usage: 3.8 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Read data from Excel file\n",
    "gpr = pd.read_excel('../data/raw/data_gpr_export.xls', sheet_name='Sheet1', index_col=None)\n",
    "\n",
    "# Rename 'month' column to 'Period'\n",
    "gpr = gpr.rename(columns={'month': 'Period'})\n",
    "\n",
    "# Convert 'Period' to datetime format\n",
    "gpr['Period'] = pd.to_datetime(gpr['Period'], format='%YM%m')\n",
    "\n",
    "# Filter the rows where 'Period' is between 2010-01-01 and 2023-08-01\n",
    "gpr = gpr[(gpr['Period'] >= '2010-01-01') & (gpr['Period'] <= '2023-08-01')]\n",
    "\n",
    "# Select only the 'Period' and 'GPR' columns\n",
    "gpr = gpr[['Period', 'GPR']]\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(gpr.head())\n",
    "\n",
    "# Display a concise summary of the DataFrame\n",
    "print(gpr.info())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T07:44:44.510146Z",
     "start_time": "2024-08-17T07:44:44.379534Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "GEM -- Global economic monitor index https://databank.worldbank.org/source/global-economic-monitor-(gem)#"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "\n",
    "# Read data from Excel file\n",
    "gem = pd.read_excel('../data/raw/P_Data_Extract_From_Global_Economic_Monitor_(GEM)-2.xlsx', sheet_name='Data', index_col=None)\n",
    "\n",
    "# Transpose the DataFrame and select the data starting from the fourth row\n",
    "gem = gem.transpose().iloc[3:]\n",
    "\n",
    "# Set the first row as the header\n",
    "gem.columns = gem.iloc[0]\n",
    "gem = gem[1:]\n",
    "\n",
    "# Move the existing index to a regular column\n",
    "gem.reset_index(inplace=True)\n",
    "\n",
    "# Rename the column 'index' to 'Period'\n",
    "gem = gem.rename(columns={'index': 'Period'})\n",
    "\n",
    "# Extract the part before the blank space in the 'Period' column\n",
    "gem['Period'] = gem['Period'].str.split().str[0]\n",
    "\n",
    "# Convert 'Period' to datetime format\n",
    "gem['Period'] = pd.to_datetime(gem['Period'], format='%YM%m')\n",
    "\n",
    "# Filter rows where 'Period' is between 2010-01-01 and 2023-08-01\n",
    "gem = gem[(gem['Period'] >= '2010-01-01') & (gem['Period'] <= '2023-08-01')]\n",
    "\n",
    "# Replace '..' with NA\n",
    "gem.replace('..', np.nan, inplace=True)\n",
    "\n",
    "# Drop columns with all NaN values\n",
    "gem = gem.dropna(axis=1, how='all')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T07:44:44.579663Z",
     "start_time": "2024-08-17T07:44:44.511164Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "\n",
    "# Read data\n",
    "GEPU = pd.read_csv('../data/raw/GEPUCURRENT.csv', encoding='unicode_escape')\n",
    "\n",
    "# Rename columns\n",
    "GEPU = GEPU.rename(columns={'DATE': 'Period','GEPUCURRENT':'GEPU'})\n",
    "\n",
    "# Keep only Period  between 2000M01 and 2023M09\n",
    "GEPU['Period'] = pd.to_datetime(GEPU['Period'])\n",
    "GEPU = GEPU[(GEPU['Period'] >= '2010-01-01') & (GEPU['Period'] <= '2023-08-01')]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T07:44:44.588100Z",
     "start_time": "2024-08-17T07:44:44.581201Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Period   CPTOTSAXN   DPANUSSPB  DXGSRMRCHSACD  DMGSRMRCHSACD  \\\n",
      "0 2010-01-01  100.000000  273.668678   1.094645e+06   1.802235e+06   \n",
      "1 2010-02-01  100.147360  275.136917   1.108186e+06   1.853262e+06   \n",
      "2 2010-03-01  100.297261  273.147971   1.128765e+06   1.819304e+06   \n",
      "3 2010-04-01  100.477298  271.460411   1.132969e+06   1.811889e+06   \n",
      "4 2010-05-01  100.611906  274.960784   1.118128e+06   1.774453e+06   \n",
      "\n",
      "      IPTOTSAKD    IMPCOV        NEER        REER  RETSALESSA       TOTRESV  \\\n",
      "0  1.279704e+12  4.880311   99.710300   99.882075  100.970001  8.795469e+06   \n",
      "1  1.283712e+12  4.751241  100.058497  100.144656  101.121526  8.805293e+06   \n",
      "2  1.300778e+12  4.882158   99.910024   99.868581  102.100177  8.882128e+06   \n",
      "3  1.309634e+12  4.978065   99.826979   99.736114   95.659314  9.019701e+06   \n",
      "4  1.319176e+12  5.057788  100.486460  100.390645   96.108964  8.974806e+06   \n",
      "\n",
      "   UNEMPSA_        GEPU  \n",
      "0  8.266556  113.055131  \n",
      "1  8.206897  111.376776  \n",
      "2  8.188579  107.563775  \n",
      "3  8.210219  103.827844  \n",
      "4  8.116854  146.925561  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 164 entries, 0 to 163\n",
      "Data columns (total 13 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   Period         164 non-null    datetime64[ns]\n",
      " 1   CPTOTSAXN      164 non-null    float64       \n",
      " 2   DPANUSSPB      145 non-null    float64       \n",
      " 3   DXGSRMRCHSACD  164 non-null    float64       \n",
      " 4   DMGSRMRCHSACD  164 non-null    float64       \n",
      " 5   IPTOTSAKD      164 non-null    float64       \n",
      " 6   IMPCOV         164 non-null    float64       \n",
      " 7   NEER           164 non-null    float64       \n",
      " 8   REER           164 non-null    float64       \n",
      " 9   RETSALESSA     164 non-null    float64       \n",
      " 10  TOTRESV        164 non-null    float64       \n",
      " 11  UNEMPSA_       164 non-null    float64       \n",
      " 12  GEPU           164 non-null    float64       \n",
      "dtypes: datetime64[ns](1), float64(12)\n",
      "memory usage: 16.8 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Merge 'gem' with 'GEPU' on the 'Period' column\n",
    "gem = pd.merge(gem, GEPU, on='Period')\n",
    "\n",
    "# Keep only the specified columns\n",
    "gem = gem[['Period', 'CPTOTSAXN', 'DPANUSSPB', 'DXGSRMRCHSACD', 'DMGSRMRCHSACD', 'IPTOTSAKD', 'IMPCOV', 'NEER', 'REER', 'RETSALESSA', 'TOTRESV', 'UNEMPSA_', 'GEPU']]\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(gem.head())\n",
    "print(gem.info())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T07:44:44.599325Z",
     "start_time": "2024-08-17T07:44:44.588945Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Construct feature matrix"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "# Merge tpu, gpr, gem into the features data\n",
    "merged_data = pd.merge(tpu, gpr, on='Period')\n",
    "features = pd.merge(merged_data, gem, on='Period')\n",
    "\n",
    "# Save the merged DataFrame to a CSV file\n",
    "features.to_csv('../data/processed/features.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T07:44:44.611585Z",
     "start_time": "2024-08-17T07:44:44.597942Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 164 entries, 0 to 163\n",
      "Data columns (total 15 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   Period         164 non-null    datetime64[ns]\n",
      " 1   TPU            164 non-null    float64       \n",
      " 2   GPR            164 non-null    float64       \n",
      " 3   CPTOTSAXN      164 non-null    float64       \n",
      " 4   DPANUSSPB      145 non-null    float64       \n",
      " 5   DXGSRMRCHSACD  164 non-null    float64       \n",
      " 6   DMGSRMRCHSACD  164 non-null    float64       \n",
      " 7   IPTOTSAKD      164 non-null    float64       \n",
      " 8   IMPCOV         164 non-null    float64       \n",
      " 9   NEER           164 non-null    float64       \n",
      " 10  REER           164 non-null    float64       \n",
      " 11  RETSALESSA     164 non-null    float64       \n",
      " 12  TOTRESV        164 non-null    float64       \n",
      " 13  UNEMPSA_       164 non-null    float64       \n",
      " 14  GEPU           164 non-null    float64       \n",
      "dtypes: datetime64[ns](1), float64(14)\n",
      "memory usage: 19.3 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Display a concise summary of the DataFrame\n",
    "print(features.info())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T07:44:44.612176Z",
     "start_time": "2024-08-17T07:44:44.609072Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T07:44:44.613020Z",
     "start_time": "2024-08-17T07:44:44.611014Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Stock Price: Semiconductor ETF \n",
    "https://finance.yahoo.com/quote/SOXX/"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Period  etf_price\n",
      "101 2010-01-01  12.225553\n",
      "102 2010-02-01  13.201204\n",
      "103 2010-03-01  14.057395\n",
      "104 2010-04-01  14.341842\n",
      "105 2010-05-01  13.403166\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 164 entries, 101 to 264\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype         \n",
      "---  ------     --------------  -----         \n",
      " 0   Period     164 non-null    datetime64[ns]\n",
      " 1   etf_price  164 non-null    float64       \n",
      "dtypes: datetime64[ns](1), float64(1)\n",
      "memory usage: 3.8 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Read the ETF price data from CSV\n",
    "etf_price = pd.read_csv('../data/raw/SOXX.csv')\n",
    "\n",
    "# Rename columns and select needed columns\n",
    "etf_price['Period'] = pd.to_datetime(etf_price['Date'])\n",
    "etf_price['etf_price'] = etf_price['Adj Close']\n",
    "etf_price = etf_price[['Period', 'etf_price']]\n",
    "\n",
    "# Filter the 'Period' column to keep data between 2010-01-01 and 2023-08-01\n",
    "etf_price = etf_price[(etf_price['Period'] >= '2010-01-01') & (etf_price['Period'] <= '2023-08-01')]\n",
    "\n",
    "# Display the first few rows and a concise summary of the DataFrame\n",
    "print(etf_price.head())\n",
    "print(etf_price.info())\n",
    "\n",
    "# Save the processed data to a CSV file\n",
    "etf_price.to_csv('../data/processed/etf_price.csv', index=False, header=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T07:44:44.625356Z",
     "start_time": "2024-08-17T07:44:44.614074Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T07:44:44.626884Z",
     "start_time": "2024-08-17T07:44:44.624071Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
